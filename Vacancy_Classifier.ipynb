{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vacancy Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCVPAX5VPdcm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7c5b98b1-8e09-41a0-d293-6e7793d35659"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lETLNf45PExW",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "8f982fe1-ff01-4506-ec6d-0f1516004688"
      },
      "source": [
        "from google.colab import files\n",
        "_ = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a7b352b5-ae83-4d64-8ba3-ad80d2039b99\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a7b352b5-ae83-4d64-8ba3-ad80d2039b99\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving 040920 Description 2d animator.csv to 040920 Description 2d animator.csv\n",
            "Saving 040920 Description Motion Designer.csv to 040920 Description Motion Designer.csv\n",
            "Saving 080920 Description 2d animator.csv to 080920 Description 2d animator.csv\n",
            "Saving 080920 Description Motion Designer.csv to 080920 Description Motion Designer.csv\n",
            "Saving 200820 Description 2d animator.csv to 200820 Description 2d animator.csv\n",
            "Saving 200820 Description Motion Designer.csv to 200820 Description Motion Designer.csv\n",
            "Saving 200820 description test.csv to 200820 description test.csv\n",
            "Saving 240820 Description 2d animator.csv to 240820 Description 2d animator.csv\n",
            "Saving 240820 Description Motion Designer.csv to 240820 Description Motion Designer.csv\n",
            "Saving 260820 Description 2d animator.csv to 260820 Description 2d animator.csv\n",
            "Saving 260820 Description Motion Designer.csv to 260820 Description Motion Designer.csv\n",
            "Saving 290820 Description 2d animator.csv to 290820 Description 2d animator.csv\n",
            "Saving 290820 Description Motion Designer.csv to 290820 Description Motion Designer.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn4pc6i4PiG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "MIN_HEADER_LEN = 0\n",
        "MAX_HEADER_LEN = 5000\n",
        "# trying to not check header length\n",
        "MIN_SECTIONS = 2\n",
        "MAX_SECTIONS = 10\n",
        "\n",
        "def strip_for_all(list_of_str : list, func=str.strip, sensfull_length=4):\n",
        "    return [func(elem) for elem in list_of_str if len(elem) >= sensfull_length]\n",
        "\n",
        "def return_first_items(input_dict : OrderedDict):\n",
        "    try:\n",
        "        first_out_key = list(input_dict.keys())[0]\n",
        "    except IndexError:\n",
        "        return (OrderedDict())\n",
        "    try:\n",
        "        first_inn_key = list(input_dict[first_out_key].keys())[0]\n",
        "    except IndexError:\n",
        "        return (OrderedDict())\n",
        "    return (input_dict[first_out_key][first_inn_key])\n",
        "\n",
        "def segmentation_by_terminals(full_text : str, keyword_to_paragraph : {}, terminals=[\"**\"], small_terminals=[\"*\", r\"\\-\", \"\\n\"]):\n",
        "    # trying cut full text in segments [T,h,T,h,T], where h - headear, T - text\n",
        "    # then evaluate quality of cutting\n",
        "\n",
        "    segmentations_variants = OrderedDict()\n",
        "\n",
        "    #TODO: Check results by different terminals\n",
        "    for terminal in terminals:\n",
        "        segmentations_variants[terminal] = OrderedDict()\n",
        "        segments = full_text.split(terminal)\n",
        "        segments = strip_for_all(segments)\n",
        "\n",
        "        for sub_terminal in small_terminals:\n",
        "            segmentations_variants[terminal][sub_terminal] = OrderedDict()\n",
        "            max_sections = 0\n",
        "\n",
        "            for i in range(len(segments)):\n",
        "                sub_segments = segments[i].split(sub_terminal)\n",
        "                sub_segments = strip_for_all(sub_segments)\n",
        "                if len(sub_segments) >= MIN_SECTIONS:\n",
        "                    if i > 0:\n",
        "                        if MIN_HEADER_LEN <= len(segments[i-1]) <= MAX_HEADER_LEN:\n",
        "                            segmentations_variants[terminal][sub_terminal][segments[i-1]] = sub_segments\n",
        "                            if len(sub_segments) > max_sections:\n",
        "                                max_sections = len(sub_segments)\n",
        "                    elif i == 0:\n",
        "                        segmentations_variants[terminal][sub_terminal][\"headless\"] = sub_segments\n",
        "\n",
        "            if not segmentations_variants[terminal][sub_terminal]:\n",
        "                del segmentations_variants[terminal][sub_terminal]\n",
        "            if max_sections >= MAX_SECTIONS:\n",
        "                del segmentations_variants[terminal][sub_terminal]\n",
        "\n",
        "        if not segmentations_variants[terminal]:\n",
        "            del segmentations_variants[terminal]\n",
        "\n",
        "    return (segmentations_variants)\n",
        "\n",
        "def is_nan_or_empty(a : str):\n",
        "    if (a != a):\n",
        "        return (True)\n",
        "    else:\n",
        "        return (not bool(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Z2UJEjmQJdV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "d25bd83e-a75e-41fb-bb3c-ced6b0a742a0"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "\n",
        "for (dirpath, dirnames, filenames) in os.walk(os.getcwd()):\n",
        "    for filename in filenames:\n",
        "        if filename.endswith(\"csv\"):\n",
        "            print (filename)\n",
        "            temp_df = pd.read_csv(filename)\n",
        "            df = pd.concat([df, temp_df])\n",
        "    break\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "080920 Description 2d animator.csv\n",
            "290820 Description 2d animator.csv\n",
            "240820 Description 2d animator.csv\n",
            "260820 Description Motion Designer.csv\n",
            "240820 Description Motion Designer.csv\n",
            "260820 Description 2d animator.csv\n",
            "290820 Description Motion Designer.csv\n",
            "080920 Description Motion Designer.csv\n",
            "040920 Description Motion Designer.csv\n",
            "200820 Description 2d animator.csv\n",
            "200820 Description Motion Designer.csv\n",
            "200820 description test.csv\n",
            "040920 Description 2d animator.csv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>description</th>\n",
              "      <th>snippet.requirement</th>\n",
              "      <th>snippet.responsibility</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Всем привет! Мы компания Adme и сейчас мы в по...</td>\n",
              "      <td>Отличное владение After Effects (также рассмат...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\nWhaleapp — ведущая компания в мире создани...</td>\n",
              "      <td>Имеешь опыт работы со скелетной анимацией от 1...</td>\n",
              "      <td>Создание рига и анимаций в Spine 2D. Создание ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\nMotionads — креативная студия , специализи...</td>\n",
              "      <td>Мы ждем, что ты уверенно работаешь в After Eff...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\n **Чем предстоит заниматься:**\\n\\n  * Созд...</td>\n",
              "      <td>Опыт работы на позиции аниматора от полугода. ...</td>\n",
              "      <td>Создание анимаций для мобильных игр в Spine: м...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>\\n\\n **Задачи:**\\n\\n  * Создание анимаций для ...</td>\n",
              "      <td>Опыт работы на позиции аниматора от полугода. ...</td>\n",
              "      <td>Создание анимаций для мобильных игр в Spine: м...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ... Unnamed: 5\n",
              "0           0  ...        NaN\n",
              "1           0  ...        NaN\n",
              "2           0  ...        NaN\n",
              "3           0  ...        NaN\n",
              "4           0  ...        NaN\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2GK4buEHhGf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BagOfWords_Vectorizer():\n",
        "\n",
        "    def __init__(self, full_text : str, languages=[\"russian\",\"english\"], DEBUG=True):\n",
        "        self.DEBUG = DEBUG\n",
        "        self.vacabulary = re.sub(r\"[^a-zA-ZА-Яа-яЁё]\", \" \", full_text.lower())\n",
        "        self.stopwords = nltk.corpus.stopwords.words(languages)\n",
        "        self.vacabulary = sorted(set(nltk.tokenize.word_tokenize(self.vacabulary)) - set(self.stopwords))\n",
        "\n",
        "    def str_to_vec(self, target_str : str):\n",
        "        get_words = re.sub(r\"[^a-zA-ZА-Яа-яЁё]\", \" \", target_str.lower())\n",
        "        get_words = set(nltk.tokenize.word_tokenize(get_words)) - set(self.stopwords)\n",
        "        vector = np.zeros(len(self.vacabulary))\n",
        "        indexes = []\n",
        "        for word in get_words:\n",
        "            try:\n",
        "                indexes.append(self.vacabulary.index(word))\n",
        "            except ValueError:\n",
        "                if self.DEBUG:\n",
        "                    message = 'there is no such word as \"{}\" in dictinary. There is some mistake here'.format(word)\n",
        "                    raise ValueError(message)\n",
        "                else:\n",
        "                    print ('there is no such word as \"{}\" in dictinary. There is some mistake here'.format(word))\n",
        "        vector[indexes] = 1\n",
        "        return (vector)\n",
        "\n",
        "    def vec_to_str(self, vector : np.array):\n",
        "        words = []\n",
        "        for i in range(len(vector)):\n",
        "            if vector[i]:\n",
        "                words.append(self.vacabulary[i])\n",
        "        return (words)\n",
        "\n",
        "    def str_to_str(self, target_str : str):\n",
        "        get_words = re.sub(r\"[^a-zA-ZА-Яа-яЁё]\", \" \", target_str.lower())\n",
        "        get_words = set(nltk.tokenize.word_tokenize(get_words)) - set(self.stopwords)\n",
        "        return (get_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKIcQbSq_rZ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_marks_for_headers(df : pd.DataFrame, vectorizer : BagOfWords_Vectorizer, DEBUG=False, my_debug=[]):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        segments = return_first_items(segmentation_by_terminals(df[\"description\"].iloc[i], keyword_to_paragraph={}))\n",
        "        tails_vec = []\n",
        "        heads_vec = []\n",
        "        indexes = []\n",
        "        for key in segments.keys():\n",
        "            tails_vec.append(vectorizer.str_to_vec(\" \".join(segments[key])))\n",
        "            heads_vec.append(vectorizer.str_to_vec(key))\n",
        "        if tails_vec:\n",
        "            tails_vec = np.array(tails_vec)\n",
        "            heads_vec = np.array(heads_vec)\n",
        "            indexes = list(range(tails_vec.shape[0]))\n",
        "            #print (indexes)\n",
        "            if not is_nan_or_empty(df[\"snippet.requirement\"].iloc[i]):\n",
        "                vec_req = vectorizer.str_to_vec(df[\"snippet.requirement\"].iloc[i])\n",
        "                cosine = ((tails_vec * vec_req).sum(axis=1)/vec_req.sum())\n",
        "                index = cosine.argmax()\n",
        "                X.append(heads_vec[index])\n",
        "                Y.append(np.array([1,0,0,0]))  # \"requirment\" class, \"responsibility\" class, \"other\" class, \"none above\" class\n",
        "                indexes.remove(index)\n",
        "            if not is_nan_or_empty(df[\"snippet.responsibility\"].iloc[i]):\n",
        "                vec_res = vectorizer.str_to_vec(df[\"snippet.responsibility\"].iloc[i])\n",
        "                cosine = ((tails_vec * vec_res).sum(axis=1)/vec_res.sum())\n",
        "                index = cosine.argmax()\n",
        "                try:\n",
        "                    indexes.remove(index)\n",
        "                    Y.append(np.array([0,1,0,0]))\n",
        "                    X.append(heads_vec[index])\n",
        "                except ValueError:\n",
        "                    if DEBUG:\n",
        "                        Y.append(np.array([1,1,0,0]))\n",
        "                        my_debug.append(i)\n",
        "                        print (my_debug)\n",
        "                        print (\"clashing indexes. Requirements and responsibility vector have same closest vector\")\n",
        "                    else:\n",
        "                        # just throwing away problem records\n",
        "                        # there can be paragraphs with one item\n",
        "                        # special symbols across paragraph\n",
        "                        # or both snippet in one paragraph\n",
        "                        del X[-1]\n",
        "                        del Y[-1]\n",
        "            for index in indexes:\n",
        "                X.append(heads_vec[index])\n",
        "                Y.append(np.array([0,0,1,0]))\n",
        "    X = np.row_stack(X)\n",
        "    Y = np.row_stack(Y)\n",
        "    return (X, Y)\n",
        "\n",
        "\n",
        "full_text = str()\n",
        "for i in range(len(df[\"description\"])):\n",
        "    #TODO: check for none?\n",
        "    full_text += df[\"description\"].iloc[i]\n",
        "full_text += \" headless\" #add my header to vocabulary\n",
        "\n",
        "vectorizer = BagOfWords_Vectorizer(full_text=full_text, DEBUG=False)\n",
        "# print (\"full text length is\",len(full_text))\n",
        "del (full_text)\n",
        "\n",
        "X, Y = get_marks_for_headers(df, vectorizer, DEBUG=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPHlUePC2oA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
        "clf.fit(X_train, Y_train)\n",
        "\n",
        "Y_pred = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RCy-6g6rP_a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22d442a5-1bdf-4ea9-af2c-af8edc4947e7"
      },
      "source": [
        "(Y_pred == Y_test).sum() / (Y_pred == Y_test).size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8992172211350293"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "795zO1Yl6C0O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d134deaa-2a73-4f33-d90b-2721bd3865ce"
      },
      "source": [
        "feature_names = vectorizer.vec_to_str(np.ones(len(vectorizer.vacabulary)))\n",
        "text_representation = tree.export_text(clf, feature_names=feature_names)\n",
        "print(text_representation)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|--- требования <= 0.50\n",
            "|   |--- обязанности <= 0.50\n",
            "|   |   |--- задачи <= 0.50\n",
            "|   |   |   |--- предстоит <= 0.50\n",
            "|   |   |   |   |--- experience <= 0.50\n",
            "|   |   |   |   |   |--- заниматься <= 0.50\n",
            "|   |   |   |   |   |   |--- ожидаем <= 0.50\n",
            "|   |   |   |   |   |   |   |--- предлагаем <= 0.50\n",
            "|   |   |   |   |   |   |   |   |--- условия <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- fired <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 3\n",
            "|   |   |   |   |   |   |   |   |   |--- fired >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- условия >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- работы <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |   |--- работы >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- предлагаем >  0.50\n",
            "|   |   |   |   |   |   |   |   |--- нашего <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- атмосферы <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |   |--- атмосферы >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- нашего >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- ожидаем >  0.50\n",
            "|   |   |   |   |   |   |   |--- кандидатов <= 0.50\n",
            "|   |   |   |   |   |   |   |   |--- кандидата <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |   |--- кандидата >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |   |   |--- кандидатов >  0.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 1\n",
            "|   |   |   |   |   |--- заниматься >  0.50\n",
            "|   |   |   |   |   |   |--- будете <= 0.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- будете >  0.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- experience >  0.50\n",
            "|   |   |   |   |   |--- class: 1\n",
            "|   |   |   |--- предстоит >  0.50\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- задачи >  0.50\n",
            "|   |   |   |--- какие <= 0.50\n",
            "|   |   |   |   |--- которые <= 0.50\n",
            "|   |   |   |   |   |--- твои <= 0.50\n",
            "|   |   |   |   |   |   |--- перспективе <= 0.50\n",
            "|   |   |   |   |   |   |   |--- стандартных <= 0.50\n",
            "|   |   |   |   |   |   |   |   |--- проекте <= 0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |   |--- проекте >  0.50\n",
            "|   |   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |   |--- стандартных >  0.50\n",
            "|   |   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |   |--- перспективе >  0.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- твои >  0.50\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- которые >  0.50\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- какие >  0.50\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |--- обязанности >  0.50\n",
            "|   |   |--- основные <= 0.50\n",
            "|   |   |   |--- ваши <= 0.50\n",
            "|   |   |   |   |--- должностные <= 0.50\n",
            "|   |   |   |   |   |--- animator <= 0.50\n",
            "|   |   |   |   |   |   |--- твои <= 0.50\n",
            "|   |   |   |   |   |   |   |--- class: 3\n",
            "|   |   |   |   |   |   |--- твои >  0.50\n",
            "|   |   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |   |--- animator >  0.50\n",
            "|   |   |   |   |   |   |--- class: 0\n",
            "|   |   |   |   |--- должностные >  0.50\n",
            "|   |   |   |   |   |--- class: 0\n",
            "|   |   |   |--- ваши >  0.50\n",
            "|   |   |   |   |--- class: 0\n",
            "|   |   |--- основные >  0.50\n",
            "|   |   |   |--- class: 0\n",
            "|--- требования >  0.50\n",
            "|   |--- кандидату <= 0.50\n",
            "|   |   |--- важные <= 0.50\n",
            "|   |   |   |--- обязательные <= 0.50\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |   |--- обязательные >  0.50\n",
            "|   |   |   |   |--- class: 1\n",
            "|   |   |--- важные >  0.50\n",
            "|   |   |   |--- class: 1\n",
            "|   |--- кандидату >  0.50\n",
            "|   |   |--- class: 1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}